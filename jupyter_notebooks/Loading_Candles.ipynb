{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Entering variables"
      ],
      "metadata": {
        "id": "nxFlJGrHLa6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZthELvaYNoiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6bef1a-795b-45e4-f0be-ce066956341f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your API key: ··········\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import requests\n",
        "import datetime\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import getpass\n",
        "\n",
        "tickers = ['XOM', 'CVX', 'COP', 'EOD', 'EPD', 'MPC', 'PSX', 'OXY', 'ET', 'WMB',\n",
        "           'VLO', 'OKE']\n",
        "api_key = getpass.getpass('Enter your API key: ')\n",
        "# availiable candle size: 1 (1 minute), 5 (5 minutes), 15 (1 minutes), 30 (30 minutes), 60 (60 minutes), 24 (daily)\n",
        "candle_size = 24\n",
        "db_path = \"/content/drive/MyDrive/databases/candles_history.db\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Receiving JSON candles and save to Database"
      ],
      "metadata": {
        "id": "jpBwGaH_XyBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker in tickers:\n",
        "  data = get_daily_candles(ticker, api_key)\n",
        "  candles = candles_processing(data, ticker, candle_size)\n",
        "  candles_save(candles, db_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDtCNPFmXxRB",
        "outputId": "26be2149-835d-478f-a68e-6835d43e4d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Candle model class"
      ],
      "metadata": {
        "id": "IjRYt5YuKshn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Candle():\n",
        "  @property\n",
        "  def id(self):\n",
        "    pass\n",
        "\n",
        "  @property\n",
        "  def date_time(self):\n",
        "    pass\n",
        "\n",
        "  @property\n",
        "  def ticker(self):\n",
        "    pass\n",
        "\n",
        "  @property\n",
        "  def size(self):\n",
        "    pass\n",
        "\n",
        "  @property\n",
        "  def source(self):\n",
        "    pass\n",
        "\n",
        "  @property\n",
        "  def open(self):\n",
        "    pass\n",
        "\n",
        "  @property\n",
        "  def max(self):\n",
        "    pass\n",
        "\n",
        "  @property\n",
        "  def min(self):\n",
        "    pass\n",
        "\n",
        "  @property\n",
        "  def close(self):\n",
        "    pass\n",
        "\n",
        "  @property\n",
        "  def volume(self):\n",
        "    pass\n",
        "\n",
        "  def __init__(self, id: str, date_time: datetime.datetime, ticker: str, size: int,\n",
        "            source: str, open: float, max: float, min: float, close: float,\n",
        "            volume: int):\n",
        "    self._id = id\n",
        "    self._date_time = date_time\n",
        "    self._ticker = ticker\n",
        "    self._size = size\n",
        "    self._source = source\n",
        "    self._open = open\n",
        "    self._max = max\n",
        "    self._min = min\n",
        "    self._close = close\n",
        "    self._volume = volume\n",
        "\n",
        "  def __str__(self) -> str:\n",
        "    return f\"datetime: {self._date_time}, open: {self._open}, high: {self._max}, low: {self._min}, close: {self._close}, volume: {self._volume}\"\n",
        "\n",
        "  def __repr__(self) -> str:\n",
        "    return f\"datetime: {self._date_time}, open: {self._open}, high: {self._max}, low: {self._min}, close: {self._close}, volume: {self._volume}\""
      ],
      "metadata": {
        "id": "0LEY8p2mNvIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function for processing received candles JSON"
      ],
      "metadata": {
        "id": "vbtwCVQBJDbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def candles_processing(data, ticker, candle_size):\n",
        "  candle_keys = [key for key in data['Time Series (Daily)']]\n",
        "  candles = []\n",
        "  source = 'global'\n",
        "  for key in candle_keys:\n",
        "    id = str(key) + str(ticker) + str(candle_size)\n",
        "    candle = Candle(id,\n",
        "                    datetime.datetime.strptime(key, '%Y-%m-%d'),\n",
        "                    ticker,\n",
        "                    candle_size,\n",
        "                    source,\n",
        "                    float(data['Time Series (Daily)'][key]['1. open']),\n",
        "                    float(data['Time Series (Daily)'][key]['2. high']),\n",
        "                    float(data['Time Series (Daily)'][key]['3. low']),\n",
        "                    float(data['Time Series (Daily)'][key]['4. close']),\n",
        "                    int(data['Time Series (Daily)'][key]['5. volume']))\n",
        "    candles.append(candle)\n",
        "  return candles"
      ],
      "metadata": {
        "id": "-1t5dlOmT5mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Candles request functions"
      ],
      "metadata": {
        "id": "kUD3RtkEK8DG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_daily_candles(ticker, api_key):\n",
        "  url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={ticker}&outputsize=full&apikey={api_key}'\n",
        "  r = requests.get(url)\n",
        "  data = r.json()\n",
        "  return data"
      ],
      "metadata": {
        "id": "aP3uJoTkK7d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Database saving function"
      ],
      "metadata": {
        "id": "FFDf0Z9_MzQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def candles_save(candles, path):\n",
        "  connect_to_drive()\n",
        "  conn = sqlite3.connect(path)\n",
        "  cursor = conn.cursor()\n",
        "\n",
        "  cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS candles (\n",
        "    id TEXT PRIMARY KEY,\n",
        "    date_time DATETIME,\n",
        "    ticker TEXT,\n",
        "    size INTEGER,\n",
        "    source TEXT,\n",
        "    open REAL,\n",
        "    max REAL,\n",
        "    min REAL,\n",
        "    close REAL,\n",
        "    volume INTEGER\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "  candles_to_insert = [(candle._id, candle._date_time, candle._ticker,\n",
        "                        candle._size, candle._source, candle._open,\n",
        "                        candle._max, candle._min, candle._close, candle._volume) for candle in candles]\n",
        "  try:\n",
        "    cursor.executemany('''\n",
        "      INSERT OR IGNORE INTO candles (id, date_time, ticker, size, source, open, max, min, close, volume)\n",
        "      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "      ''', candles_to_insert)\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "  except sqlite3.Error as e:\n",
        "    print(f\"Error: {e}\")\n",
        "  finally:\n",
        "        conn.close()"
      ],
      "metadata": {
        "id": "MTQkOqpOMy1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conntect to Drive"
      ],
      "metadata": {
        "id": "yHUASY86Nc5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def connect_to_drive():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cNSV-NDrNfv1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}